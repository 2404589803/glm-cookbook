{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Use GLM-4 API to fine-tune model with LORA method\n",
    "\n",
    "**This tutorial is available in English and is attached below the Chinese explanation**\n",
    "\n",
    "此代码将展示如何调用 GLM-4 API 来使用LORA的方法对一个 glm 模型进行微调。你将会在本代码中学到：\n",
    "1. 微调数据集的格式\n",
    "2. 如何上传微调的数据集\n",
    "3. 如何管理和查看自己的微调数据集\n",
    "4. 如何设置超参数并开始微调模型\n",
    "5. 如何调用微调后的模型\n",
    "\n",
    "This code will show how to call the GLM-4 API to fine-tune a glm model using LORA methods. What you will learn in this code:\n",
    "1. Fine-tune the format of the data set\n",
    "2. How to upload fine-tuned dataset\n",
    "3. How to manage and view your own fine-tuning data set\n",
    "4. How to set hyperparameters and start fine-tuning the model\n",
    "5. How to call the fine-tuned model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62da0bf568d4e89f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Set API Keys and Client\n",
    "首先，我们设置好 API KEY，并将这个API KEY设置为环境变量，这样我们就可以在代码中直接调用了。\n",
    "\n",
    "First, we set up the API KEY and set this API KEY as an environment variable so that we can call it directly in the code."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ceb4590d0e68f177"
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from zhipuai import ZhipuAI\n",
    "\n",
    "os.environ[\"ZHIPUAI_API_KEY\"] = \"your zhipuAI API Key\"\n",
    "client = ZhipuAI()"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-04T14:28:56.678860Z",
     "start_time": "2024-07-04T14:28:56.291539Z"
    }
   },
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare the dataset\n",
    "\n",
    "需要准备训练的数据集，并将其拆分为训练集和验证集。根据官方文档的文件规则，我们需要将要整理完后的数据集格式如下：\n",
    "\n",
    "We need to prepare a training dataset and split it into a training set and a validation set. According to the file rules of the official document, we need to format the dataset to be organized as follows:\n",
    "```json lines\n",
    "{\"messages\": [{\"role\": \"user\", \"content\": \"你是专门进行实体抽取的专家。请从input中抽取出符合schema定义的实体，不存在的实体类型返回空列表。请按照JSON字符串的格式回答。schema:['address','book','company','game','government','movie']，input:中新网12日22日电据中国银监会网站消息，日前，银监会通知印发了《银行与信托公司业务合作指引》，\"}, {\"role\": \"assistant\", \"content\": \"{\\\"address\\\":[],\\\"book\\\":[\\\"中新网\\\",\\\"《银行与信托公司业务合作指引》\\\"],\\\"company\\\":[],\\\"game\\\":[],\\\"government\\\":[\\\"中国银监会\\\",\\\"银监会\\\"],\\\"movie\\\":[]}\"}]}\n",
    "{\"messages\": [{\"role\": \"user\", \"content\": \"你是专门进行实体抽取的专家。请从input中抽取出符合schema定义的实体，不存在的实体类型返回空列表。请按照JSON字符串的格式回答。schema:['name','organization','position','scene']，input:此前，住房和城乡建设部副部长齐骥在谈及保障性住房需要的几大制度及政府保障工作时，\"}, {\"role\": \"assistant\", \"content\": \"{\\\"name\\\":[\\\"齐骥\\\"],\\\"organization\\\":[],\\\"position\\\":[\\\"副部长\\\"],\\\"scene\\\":[]}\"}]}\n",
    "```\n",
    "\n",
    "在这里，我们使用[实体识别数据集](./data/Reco)作为一个数据集的例子。数据集已经被分割为 `train.jsonl` 和 `dev.jsonl`。可直接用于训练。\n",
    "Here, we use the [Entity Recognition Dataset](./data/Eco) as an example of a dataset. The dataset has been split into `train. jsonl` and `dev. jsonl`. Can be directly used for training.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9915962fb3f28662"
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们可以通过API开放平台，或通过SDK提供的接口上传数据集到Zhipu AI的服务器上，并查看上传的数据集的文件列表。\n",
    "\n",
    "After the data set is converted, upload the data set to Zhipu AI's server through the interface provided by the SDK, and view the file list of the uploaded data set."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b74d4cf6b5455bc5"
  },
  {
   "cell_type": "code",
   "source": [
    "client.files.create(\n",
    "    file=open(\"data/Reco/train.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "client.files.create(\n",
    "    file=open(\"data/Reco/dev.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "client.files.list()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T00:32:17.024864Z",
     "start_time": "2024-07-05T00:31:57.017159Z"
    }
   },
   "id": "4e2f3421a6f6953f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListOfFileObject(object='list', data=[FileObject(id='file-20240705003216908-277nc', bytes=105064, created_at=1720139537000, filename='dev.jsonl', object='fd', purpose='fine-tune', status=None, status_details=None), FileObject(id='file-20240705003215910-dpk5w', bytes=2623788, created_at=1720139536000, filename='train.jsonl', object='fd', purpose='fine-tune', status=None, status_details=None), FileObject(id='file-20240623065149364-cfr4v', bytes=2623788, created_at=1719125510000, filename='train_实体识别.jsonl', object='fd', purpose='fine-tune', status=None, status_details=None), FileObject(id='file-20240623064948953-s74hl', bytes=105064, created_at=1719125389000, filename='valid_实体识别200.jsonl', object='fd', purpose='fine-tune', status=None, status_details=None), FileObject(id='file-20240410071801863-92dd2', bytes=777692, created_at=1712733482000, filename='output_3.jsonl', object='fd', purpose='fine-tune', status=None, status_details=None), FileObject(id='file-20240410055723302-8gmjz', bytes=9347, created_at=1712728643000, filename='output.jsonl', object='fd', purpose='fine-tune', status=None, status_details=None), FileObject(id='file-20240410055517226-rww8t', bytes=3484, created_at=1712728517000, filename='output.jsonl', object='fd', purpose='fine-tune', status=None, status_details=None), FileObject(id='file-20240410055458663-mxvpj', bytes=704, created_at=1712728499000, filename='output.jsonl', object='fd', purpose='fine-tune', status=None, status_details=None)], has_more=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start training using the uploaded file\n",
    "\n",
    "现在，在列表中已经找到了训练集和验证集的两个文件，我们设置好相关的参数，并上传到智谱AI的服务器上开始训练。按照[官方文档](https://open.bigmodel.cn/dev/api#finetuning)填写相关参数。我们就可以开训练了。我选择使用模型 `glm-4-0520` 进行训练。该方法跟直接在智谱AI平台上可视化训练效果相同。\n",
    "\n",
    "当前版本 SDK 中，默认使用的是 LORA 的方式进行训练。由于超参数在文档中仅开放了三个参数，分别是:\n",
    "- `learning_rate_multiplier` 学习率的倍数\n",
    "- `batch_size` 批次大小\n",
    "- `n_epochs` 训练轮数\n",
    "\n",
    "接着，我们就能开始训练了，并且，我们打印了训练的`job_id`，以便后续查看训练进度。\n",
    "\n",
    "\n",
    "Now that we have found the two files of the training set and validation set in the list, we set the relevant parameters and uploaded them to the Zhipu AI server to start training. Fill in the relevant parameters according to [official documentation](https://open.bigmodel.cn/dev/api#finetuning). We can start training. I chose to use the smallest model `chatglm3-6b` for training.\n",
    "\n",
    "In the current version of the SDK, the LORA method is used for training by default. Since the hyperparameters only open three parameters in the document, they are\n",
    "- `learning_rate_multiplier` multiple of the learning rate\n",
    "- `batch_size` batch size\n",
    "- `n_epochs` Number of training epochs\n",
    "These values have default values in the documentation, but I chose to set them myself.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27c6eec7eead67f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T12:23:31.980855Z",
     "start_time": "2024-07-06T12:23:31.975443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "job = client.fine_tuning.jobs.create(\n",
    "    model=\"glm-4-0520\",\n",
    "    training_file=\"file-20240705003215910-dpk5w\",\n",
    "    validation_file=\"file-20240705003216908-277nc\",\n",
    "    hyperparameters={\n",
    "        \"learning_rate_multiplier\": 0.5,\n",
    "        \"batch_size\": 32,\n",
    "        \"n_epochs\": 2,\n",
    "    },\n",
    "    suffix=\"zr_reco\",\n",
    ")\n",
    "job_id =job.id\n",
    "job_id"
   ],
   "id": "673fb58b02e6177c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ftjob-20240705084049260-srx27'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 查看训练进度\n",
    "我们可以查看这个训练任务的进度，以及训练的状态。 由于训练任务是异步的，因此，我们需要等待一段时间后才能看到训练的状态。其中\n",
    "- `status` 训练状态，现在是 `running`，表示正在训练\n",
    "\n",
    "由于本数据集的训练机数量较大（超过11万条数据），训练时间较长（在书写本cookbook时微调时间超过了1个小时), 因此，我在实际微调的过程使用，使用的是 `dev.jsonl` 文件进行微调和验证\n",
    "您可以自己删除部分数据集，这样能有效降低训练时间和训练的token消耗成本。\n",
    "\n",
    "We can check the progress of this training task and the status of training. Since the training task is asynchronous, we need to wait for a period of time before we can see the status of the training. in\n",
    "- `status` training status, now `running`, indicating training is in progress\n",
    "\n",
    "Since the number of training machines in this data set is large (more than 110,000 pieces of data) and the training time is long (the fine-tuning time took more than 1 hour when writing this cookbook), therefore, in the actual fine-tuning process, I used `dev.jsonl` file for fine-tuning and verification\n",
    "You can delete part of the data set yourself, which can effectively reduce training time and training token consumption costs."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "671dddd814cdb55d"
  },
  {
   "cell_type": "code",
   "source": [
    "fine_tuning_job = client.fine_tuning.jobs.retrieve(fine_tuning_job_id=job_id)\n",
    "fine_tuning_job"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-06T12:24:20.139982Z",
     "start_time": "2024-07-06T12:24:19.809800Z"
    }
   },
   "id": "bd40ce03fe32fd6e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-20240705084049260-srx27', request_id=None, created_at=1720140049, error=None, fine_tuned_model='glm-4-0520:1601347751:zr_reco:fqtvuujs', finished_at=1720150953, hyperparameters=None, model='glm-4-0520', object='fine_tuning.job', result_files=[], status='succeeded', trained_tokens=938764, training_file='file-20240705003215910-dpk5w', validation_file='file-20240705003216908-277nc', deployButton=True, experienceCenterButton=False, running_at=1720140109)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "通过等待一段时间我们再次查询，我们发现，模型已经训练完成，接下来，我们就是调用模型进行测试了。\n",
    "通过 Python SDK来查询我所有的微调任务进度，其中，这些字段的含义如下：\n",
    "- `id` 微调任务的id\n",
    "- `fine_tuned_model` 微调模型的名称\n",
    "- `request_id` 用户请求的id，默认是空\n",
    "- `created_at`,`finished_at` 任务的开始时间和结束时间,在这里都是空\n",
    "- `status` 任务的状态，现在是 `running`，表示正在训练\n",
    "\n",
    "By waiting for a while and querying again, we find that the model has been trained. Next, we call the model for testing.\n",
    "Use the Python SDK to check the progress of all my fine-tuning tasks."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffbe2fd50dbddc9e"
  },
  {
   "cell_type": "code",
   "source": [
    "client.fine_tuning.jobs.list()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-06T12:24:42.253804Z",
     "start_time": "2024-07-06T12:24:41.743324Z"
    }
   },
   "id": "8704ce3273581614",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListOfFineTuningJob(object='list', data=[FineTuningJob(id='ftjob-20240705084049260-srx27', request_id=None, created_at=1720140049, error=None, fine_tuned_model='glm-4-0520:1601347751:zr_reco:fqtvuujs', finished_at=1720150953, hyperparameters=None, model='glm-4-0520', object='fine_tuning.job', result_files=[], status='succeeded', trained_tokens=938764, training_file='file-20240705003215910-dpk5w', validation_file='file-20240705003216908-277nc', running_at=1720140109), FineTuningJob(id='ftjob-20240704173142004-h4nvk', request_id=None, created_at=1720085502, error=None, fine_tuned_model='glm-4-0520:1601347751:zrzrzrzr:zzxlmt4a', finished_at=1720101863, hyperparameters=None, model='glm-4-0520', object='fine_tuning.job', result_files=[], status='succeeded', trained_tokens=1408200, training_file='file-20240623065149364-cfr4v', validation_file='file-20240623064948953-s74hl', running_at=1720085568)], has_more=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 调用微调后的模型\n",
    "\n",
    "在完成微调任务之后，我们会得到一个新的模型，我们可以通过SDK来完成对这个模型的调用。我们首先查看一下模型列表，然后选择最新的模型进行调用。使用微调后的模型的请求方式与常规的 GLM 模型没有区别，仅需将 `model` 更换为刚才微调的模型名称即可。\n",
    "\n",
    "After completing the fine-tuning task, we will get a new model, and we can complete the call to this model through the SDK. We first check the model list, and then select the latest model to call. The request method for using the fine-tuned model is no different from the regular GLM model. You only need to replace `model` with the name of the model you just fine-tuned.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5dcb2f0413c8590"
  },
  {
   "cell_type": "code",
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-0520:1601347751:zr_reco:fqtvuujs\",\n",
    "    messages=[{\"role\": \"user\",\n",
    "               \"content\": \"你是专门进行实体抽取的专家。请从input中抽取出符合schema定义的实体，不存在的实体类型返回空列表。请按照JSON字符串的格式回答。schema:['name','organization','position','scene']，input:结果升班马热那亚首回合做客0比0逼和了桑普，但在主场却遭遇最后3分钟，最终以0比1惜败。\"}]\n",
    "\n",
    ")\n",
    "response.choices[0].message.content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-06T12:25:19.199940Z",
     "start_time": "2024-07-06T12:25:15.391447Z"
    }
   },
   "id": "71656127b9ae9da8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\":[],\"organization\":[\"热那亚\",\"桑普\"],\"position\":[],\"scene\":[]}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
