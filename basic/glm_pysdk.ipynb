{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Python SDK request ZhipuAI GLM API\n",
    "\n",
    "**This tutorial is available in English and is attached below the Chinese explanation**\n",
    "\n",
    "在熟悉使用 http 请求 glm 的 API之后，我们可以更快捷的使用 Python SDK 来请求 glm 的 API。本文将介绍如何使用 Python SDK 请求 glm 的 API。\n",
    "首先，你需要按照 [README.md](../README.md) 中的步骤安装依赖，并在这里设置你的 API_KEY。\n",
    "\n",
    "After becoming familiar with using http to request glm's API, we can use Python SDK to request glm's API more quickly. This article will introduce how to use the Python SDK to request glm's API.\n",
    "First, you need to follow the steps in [README.md](../README.md) to install the dependencies and set your API_KEY here."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "446bb790af782d79"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"ZHIPUAI_API_KEY\"] = \"your api key\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T14:38:06.036349Z",
     "start_time": "2024-01-22T14:38:06.026163Z"
    }
   },
   "id": "558c314371522260"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "\n",
    "client = ZhipuAI()\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"tell me a joke\"\n",
    "        }\n",
    "    ],\n",
    "    top_p=0.7,\n",
    "    temperature=0.9,\n",
    "    stream=False,\n",
    "    max_tokens=2000,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T14:38:06.947281Z",
     "start_time": "2024-01-22T14:38:06.030737Z"
    }
   },
   "id": "79c77ef4a6536f75"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Completion(model='glm-4', created=1705934286, choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content=\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\", role='assistant', tool_calls=None))], request_id='8313808155312936357', id='8313808155312936357', usage=CompletionUsage(prompt_tokens=9, completion_tokens=15, total_tokens=24))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T14:38:06.956341Z",
     "start_time": "2024-01-22T14:38:06.951630Z"
    }
   },
   "id": "3351d6c5035bed33"
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们已经成功获得了模型的返回，接着，如果使用流式请求，我们可以按照以下方式来请求\n",
    "\n",
    "We have successfully obtained the return of the model. Next, if we use streaming requests, we can request as follows:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cff1c2ba850dfbd1"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def print_with_typewriter_effect(text, delay=0.05):\n",
    "    for char in text:\n",
    "        print(char, end='', flush=True)\n",
    "        time.sleep(delay)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"tell me a joke\"\n",
    "        }\n",
    "    ],\n",
    "    top_p=0.7,\n",
    "    temperature=0.9,\n",
    "    stream=True,\n",
    "    max_tokens=2000,\n",
    ")\n",
    "\n",
    "if response:\n",
    "    for chunk in response:\n",
    "        content = chunk.choices[0].delta.content\n",
    "        print_with_typewriter_effect(content)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T14:40:32.298180Z",
     "start_time": "2024-01-22T14:40:28.231735Z"
    }
   },
   "id": "503c58a63e88b30e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
